{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "A100",
      "machine_shape": "hm"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gZId8y7N-aWe"
      },
      "outputs": [],
      "source": [
        "!pip install datasets\n",
        "!pip install peft"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 데이터 전처리"
      ],
      "metadata": {
        "id": "QVczo0w_1IhT"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import random"
      ],
      "metadata": {
        "id": "QVNiaiNW15eV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# gpu 사용을 위해서 사전 설정\n",
        "\n",
        "DEVICE = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "print(DEVICE)\n",
        "\n",
        "seed = 42\n",
        "random.seed(seed)\n",
        "torch.manual_seed(seed)\n",
        "torch.cuda.manual_seed(seed)\n",
        "\n",
        "torch.backends.cudnn.deterministic = True\n",
        "torch.backends.cudnn.benchmark = False"
      ],
      "metadata": {
        "id": "yd_DXWnreanS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "\n",
        "drive.mount('/content/drive')\n",
        "%cd \"/content/drive/MyDrive/2024_2학기 학교 데이터/Intro_to_AI_data\"\n",
        "\n",
        "\n",
        "# csv 파일 불러오기 및 필요한 데이터 추출\n",
        "raw_data = pd.read_csv('csrc_illegalSite_data_성균관대.csv')\n",
        "raw_data = raw_data[['keyword', 'label']]\n",
        "raw_data"
      ],
      "metadata": {
        "id": "Z26DA_kS1IU6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 결측치 확인\n",
        "raw_data.isnull().sum()"
      ],
      "metadata": {
        "id": "dB_8IGf21INW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 레이블 개수 확인"
      ],
      "metadata": {
        "id": "E-Cw-9SylUPw"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# 레이블마다의 개수 확인: 데이터개수 편향성 확인\n",
        "\n",
        "label_num = len(raw_data[\"label\"].unique())\n",
        "print(f'라벨 개수: {label_num}')\n",
        "print(f'데이터 라벨 종류: {raw_data[\"label\"].unique()}')\n",
        "\n",
        "print(f'각 라벨 개수: {raw_data[\"label\"].value_counts()}')"
      ],
      "metadata": {
        "id": "057DYg021H9_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# nn.CrossEntropy외 호환을 위해서 레이블을 0부터 시작하도록 변경\n",
        "\n",
        "raw_data['label'] = raw_data['label'] - 1\n",
        "\n",
        "label_to_site_dict = {0: \"일반사이트\", 1: \"도박사이트\", 2: \"도박 제외 불법사이트\"}\n",
        "\n",
        "print(f'각 라벨 개수: {raw_data[\"label\"].value_counts()}')"
      ],
      "metadata": {
        "id": "9zezK_7F1H5c"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 텍스트 데이터의 길이 확인\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "str_length = [len(untokenized_data) for untokenized_data in raw_data['keyword']]\n",
        "\n",
        "plt.hist(str_length, bins = 100)\n",
        "plt.title('Length of Untokenized Data')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "DdC7z5CL6fpQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "max(str_length)"
      ],
      "metadata": {
        "id": "SjIbNVqL1Hs3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(raw_data.shape)  # 전체 데이터의 크기 확인\n",
        "print(raw_data['keyword'].isnull().sum())  # text 열에 결측값이 있는지 확인\n",
        "print(raw_data['label'].isnull().sum())  # label 열에 결측값이 있는지 확인"
      ],
      "metadata": {
        "id": "HXm1xEzIQVvw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(raw_data['keyword'].shape)\n",
        "print(raw_data['label'].shape)"
      ],
      "metadata": {
        "id": "QifrfE2JUBuz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 데이터로더 정의"
      ],
      "metadata": {
        "id": "skLIizfPlaX-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from datasets import Dataset\n",
        "from transformers import AutoTokenizer\n",
        "\n",
        "\n",
        "\n",
        "# 데이터셋을 train/validation 세트로 나누기 (80%:20% 비율)\n",
        "\n",
        "# 허깅페이스 Dataset 포맷으로 변환\n",
        "dataset = Dataset.from_pandas(raw_data)\n",
        "\n",
        "\n",
        "# 전처리 함수 정의: Tokenization\n",
        "def preprocess_function(data):\n",
        "  return tokenizer(data['keyword'], truncation = True, padding = 'max_length', max_length = 512, return_tensors = 'pt')\n",
        "\n",
        "#허깅페이스에서 모델을 불러오기 위해서 checkpoint 초기화\n",
        "checkpoint = \"distilbert/distilbert-base-uncased\"\n",
        "\n",
        "tokenizer = AutoTokenizer.from_pretrained(checkpoint)\n",
        "\n",
        "\n",
        "# 텍스트 데이터 tokenization\n",
        "tokenized_data = dataset.map(preprocess_function, batched = True)\n",
        "\n",
        "\n",
        "# 'label' 컬럼을 'labels'로 변경 (허깅페이스)\n",
        "tokenized_data = tokenized_data.rename_column('label', \"labels\")\n",
        "tokenized_data = tokenized_data.rename_column('keyword', \"text\")\n",
        "\n",
        "# 데이터셋을 Trainer API로 사용하기 위해 필요한 tensor 포맷으로 설정\n",
        "tokenized_data.set_format(type=\"torch\", columns=[\"input_ids\", \"attention_mask\", \"labels\"])\n",
        "\n",
        "print(tokenized_data)"
      ],
      "metadata": {
        "id": "u2CS5o0d60U9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 훈련 데이터와 검증 데이터 분리\n",
        "\n",
        "split_data = tokenized_data.train_test_split(test_size = 0.1)\n",
        "split_data"
      ],
      "metadata": {
        "id": "m7TyGoO3_SN7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 데이터 확인\n",
        "sample = split_data['train'][0]['input_ids']\n",
        "sample_encoded = tokenizer.decode(sample, skip_special_tokens = True, clean_up_tokenization_spaces = True)\n",
        "\n",
        "print(tokenized_data, \"\\n\")\n",
        "print(sample)\n",
        "print(sample_encoded)"
      ],
      "metadata": {
        "id": "fYxe5NLA60aN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# tokenizer가 자동으로 맨 앞에 [CLS] 토큰 넣어주는 것을 확인\n",
        "\n",
        "tokenizer.cls_token_id"
      ],
      "metadata": {
        "id": "ROQ_A402Ho4i"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 모델 아키텍쳐"
      ],
      "metadata": {
        "id": "WamuIjFf1JJZ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "checkpoint = \"distilbert/distilbert-base-uncased\"\n",
        "\n",
        "tokenizer = AutoTokenizer.from_pretrained(checkpoint)"
      ],
      "metadata": {
        "id": "-1R3GWwO-keX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 모델 버전 설정\n",
        "model_ver = 4\n",
        "\n",
        "# 모델 및 history를 저장하기 위해서 path 설정\n",
        "save_model_path = \"/content/drive/MyDrive/2024_2학기 학교 데이터/Intro_to_AI_data/TwoStageDistilBERT_LoRA_ver\" + str(model_ver) + '.pt'\n",
        "\n",
        "save_hist_path = \"/content/drive/MyDrive/2024_2학기 학교 데이터/Intro_to_AI_data/TwoStageDistilBERT_LoRA_ver\" + str(model_ver) + '_hist.pt'\n",
        "\n",
        "#모델 체크포인트 및 히스토리 저장 및 불러오기 함수 정의\n",
        "def save_checkpoint(model, optimizer, scheduler, epoch, loss, save_path):\n",
        "  checkpoint = {\n",
        "      \"model_state_dict\": model.state_dict(),\n",
        "      \"optimizer_state_dict\": optimizer.state_dict(),\n",
        "      \"scheduler_state_dict\": scheduler.state_dict() if scheduler else None,\n",
        "      \"epoch\": epoch,\n",
        "      \"loss\": loss\n",
        "  }\n",
        "\n",
        "  torch.save(checkpoint, save_path)\n",
        "\n",
        "\n",
        "\n",
        "def save_hist(train_loss, train_acc, val_loss, val_acc, train_f1, val_f1, save_path):\n",
        "  hist_dict = {\n",
        "      \"train_loss_list\": train_loss,\n",
        "      \"train_acc_list\": train_acc,\n",
        "      \"val_loss_list\": val_loss,\n",
        "      \"val_acc_list\": val_acc,\n",
        "      \"train_f1_list\": train_f1,\n",
        "      \"val_f1_list\": val_f1\n",
        "  }\n",
        "\n",
        "  torch.save(hist_dict, save_path)\n",
        "\n",
        "\n",
        "def load_checkpoint(model, optimizer, scheduler, file_path, hist_path):\n",
        "  checkpoint = torch.load(file_path)\n",
        "  model.load_state_dict(checkpoint['model_state_dict'])\n",
        "  optimizer.load_state_dict(checkpoint['optimizer_state_dict'])\n",
        "  if scheduler:\n",
        "    scheduler.load_state_dict(checkpoint['scheduler_state_dict'])\n",
        "  epoch = checkpoint['epoch']\n",
        "  loss = checkpoint['loss']\n",
        "\n",
        "  hist_checkpoint = torch.load(hist_path)\n",
        "  train_loss =  hist_checkpoint[\"train_loss_list\"]\n",
        "  train_acc = hist_checkpoint[\"train_acc_list\"]\n",
        "  val_loss = hist_checkpoint[\"val_loss_list\"]\n",
        "  val_acc = hist_checkpoint[\"val_acc_list\"]\n",
        "  train_f1 = hist_checkpoint[\"train_f1_list\"]\n",
        "  val_f1 = hist_checkpoint[\"val_f1_list\"]\n",
        "\n",
        "\n",
        "  print(f\"Checkpoint loaded from {file_path}, starting from epoch {epoch+1}\")\n",
        "  return model, optimizer, scheduler, epoch + 1, loss, train_loss, train_acc, val_loss, val_acc, train_f1, val_f1  # 불러올 때 다음 에포크부터 시작"
      ],
      "metadata": {
        "id": "611GUc_Lhv0l"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#DistilBERT로 모델 불러오면 labels를 입력으로 받지 않기 때문에 DistilBertForSequenceClassification,=\n",
        "\n",
        "from transformers import DistilBertForSequenceClassification, get_scheduler\n",
        "from peft import get_peft_model, LoraConfig, TaskType\n",
        "\n",
        "\n",
        "class TwoStageDistilBERT_LoRA(nn.Module):\n",
        "  def __init__(self, distilbert_checkpoint, num_labels_1stage = 2, num_labels_2stage = 3):\n",
        "    super(TwoStageDistilBERT_LoRA, self).__init__()\n",
        "\n",
        "    \"\"\"\n",
        "    args:\n",
        "      distilbert_checkpoint: 사용할 모델의 체크포인트(str)\n",
        "      num_labels_1stage: 첫 번째 단계의 모델이 예측할 레이블 개수 (int)\n",
        "      num_labels_2stage: 두 번째 단계의 모델이 예측할 레이블 개수 (int)\n",
        "\n",
        "    \"\"\"\n",
        "\n",
        "\n",
        "    # 첫 번째 stage\n",
        "    self.distilbert1 = DistilBertForSequenceClassification.from_pretrained(distilbert_checkpoint,\n",
        "                                                                           num_labels = num_labels_1stage, ignore_mismatched_sizes = True,\n",
        "                                                                           output_hidden_states=True)\n",
        "\n",
        "    # LoRA 2번 적용\n",
        "    lora_config1 = LoraConfig(task_type = TaskType.SEQ_CLS, r = 8, lora_alpha = 32, target_modules = ['q_lin', 'v_lin'], lora_dropout = 0.1 )\n",
        "    self.distilbert1 = get_peft_model(self.distilbert1, lora_config1)\n",
        "    self.distilbert1 = get_peft_model(self.distilbert1, lora_config1)\n",
        "\n",
        "    # 두 번째 stage\n",
        "    self.distilbert2 = DistilBertForSequenceClassification.from_pretrained(distilbert_checkpoint,\n",
        "                                                                           num_labels = num_labels_2stage, ignore_mismatched_sizes = True)\n",
        "\n",
        "\n",
        "  def forward(self, input_ids,  attention_mask, labels1 = None, labels2 = None):\n",
        "    output1 = self.distilbert1(input_ids = input_ids, attention_mask = attention_mask, labels = labels1)\n",
        "    hidden1 = output1.hidden_states[-1] # 마지막 레이어의 hidden state 가져오기\n",
        "    logits1 = output1.logits\n",
        "\n",
        "    pred1 = torch.argmax(logits1, dim = 1)\n",
        "\n",
        "    output2 = self.distilbert2(inputs_embeds = hidden1, attention_mask = attention_mask, labels = labels2)\n",
        "    logits2 = output2.logits\n",
        "\n",
        "    total_loss = output1.loss + output2.loss\n",
        "\n",
        "\n",
        "    return total_loss, logits1, logits2"
      ],
      "metadata": {
        "id": "4lkbXlbJ-kkn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from torch.utils.data import DataLoader\n",
        "from tqdm import tqdm\n",
        "\n",
        "\n",
        "# 배치사이즈 설정\n",
        "batch_size = 128\n",
        "\n",
        "# 학습에 사용하기 위해 DataLoader를 통한 데이터 로드 (배치로 나누어줌)\n",
        "train_DL = DataLoader(split_data['train'], shuffle = True, batch_size = batch_size)\n",
        "val_DL = DataLoader(split_data['test'], shuffle = True, batch_size = batch_size)"
      ],
      "metadata": {
        "id": "viU6RDrC-kne"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "##################### 하이퍼파라미터 설정 #####################\n",
        "\"\"\"\n",
        "모델 중단되었으면 아래 변수를 'True'로 설정\n",
        "\"\"\"\n",
        "resume_training = True\n",
        "\n",
        "# warm-up step 확인\n",
        "# pre-trained 모델은 2%인데 너무 적어서 8%로 변경\n",
        "import math\n",
        "\n",
        "EPOCH = 25\n",
        "\n",
        "total_steps = EPOCH * len(train_DL)\n",
        "warm_up = int(total_steps * 0.08)\n",
        "\n",
        "learning_rate = 1e-4\n",
        "\n",
        "LAMBDA = 0.01\n",
        "\n",
        "model = TwoStageDistilBERT_LoRA(distilbert_checkpoint = checkpoint).to(DEVICE)\n",
        "\n",
        "lora_params = [p for p in model.parameters() if p.requires_grad]\n",
        "optimizer = torch.optim.AdamW(lora_params, weight_decay = LAMBDA, lr = learning_rate)\n",
        "scheduler = get_scheduler('cosine', optimizer = optimizer, num_warmup_steps = warm_up, num_training_steps = total_steps)\n",
        "\n",
        "\n",
        "\n",
        "#기존에 학습을 하다 중단된 경우 학습중단된 모델을 불러와서 이어서 학습\n",
        "if resume_training:\n",
        "  model, optimizer, scheduler, start_epoch, last_loss, train_loss, train_acc, val_loss, val_acc, train_f1, val_f1 = load_checkpoint(model, optimizer, scheduler, save_model_path, save_hist_path)\n",
        "\n",
        "model"
      ],
      "metadata": {
        "id": "Po4-neQU-kqn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def output2label(logits1, logits2, label_to_site_dict):\n",
        "  # logits을 보기 쉽게 바꿔주는 함수\n",
        "  N = logits1.shape[0]\n",
        "  logits1 = np.array(logits1.cpu())\n",
        "  logits2 = np.array(logits2.cpu())\n",
        "\n",
        "\n",
        "\n",
        "  output1 = np.argmax(logits1, axis = 1)\n",
        "\n",
        "  mask = (output1 != 0)\n",
        "  output2 = np.argmax(logits2[mask], axis = 1)\n",
        "  result = []\n",
        "  result_label = []\n",
        "  idx = 0\n",
        "  for out in output1:\n",
        "    if out == 0:\n",
        "      result_label.append(out)\n",
        "      result.append(label_to_site_dict[out])\n",
        "    else:\n",
        "      result_label.append(output2[idx])\n",
        "      result.append(label_to_site_dict[output2[idx]])\n",
        "      idx += 1\n",
        "\n",
        "\n",
        "  print(result)\n",
        "  print(f\"Result: {result_label}\")\n",
        "\n",
        "def output2num(logits1, logits2):\n",
        "  # logits을 레이블로 바꾸는 함수\n",
        "  # 평가측정지표를 확인하기 위한 함수에 사용됨\n",
        "  N = logits1.shape[0]\n",
        "\n",
        "  logits1 = logits1.detach().cpu().numpy()\n",
        "  logits2 = logits2.detach().cpu().numpy()\n",
        "\n",
        "  output1 = np.argmax(logits1, axis = 1)\n",
        "  mask = (output1 != 0)\n",
        "  output2 = np.argmax(logits2[mask], axis = 1)\n",
        "\n",
        "  result = np.array([])\n",
        "  idx = 0\n",
        "  for out in output1:\n",
        "    if out == 0:\n",
        "      result = np.append(result, out)\n",
        "    else:\n",
        "      result = np.append(result, output2[idx])\n",
        "      idx += 1\n",
        "\n",
        "  return result\n",
        "\n",
        "\n",
        "\n",
        "def get_metrics(logits1, logits2, labels2):\n",
        "  #정확도와 F1-score를 확인하기 위한 함수\n",
        "\n",
        "  result = output2num(logits1, logits2)\n",
        "  labels2 = np.array(labels2.cpu())\n",
        "\n",
        "  correct = (result == labels2).sum().item()\n",
        "\n",
        "  TP_mask = (result == 1)\n",
        "  TP = (labels2[TP_mask] == 1).sum().item()\n",
        "\n",
        "  FP = (labels2[TP_mask] != 1).sum().item()\n",
        "\n",
        "  FN_mask = (result != 1)\n",
        "  FN = (labels2[FN_mask] == 1).sum().item()\n",
        "\n",
        "  TN = (labels2[FN_mask] != 1).sum().item()\n",
        "\n",
        "  # 레이블이 3개여서 correct != TP + TN\n",
        "  return correct, TP, FP, FN, TN\n"
      ],
      "metadata": {
        "id": "2Idd3IGMZ3i6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 모델 테스트\n",
        "\n",
        "model.eval()\n",
        "\n",
        "with torch.no_grad():\n",
        "  for batch in train_DL:\n",
        "    batch = {key: value.to(DEVICE) for key, value in batch.items()}\n",
        "\n",
        "    labels1 = batch['labels']  # 첫 번째 분류용 라벨\n",
        "    labels1 = torch.where(labels1 ==0, 0, 1) # Binary label 처리 (0이면 0, 나머지 1, 2이면 1)\n",
        "    labels2 = batch['labels']\n",
        "\n",
        "\n",
        "    #모델에 입력\n",
        "    loss, logits1, logits2 = model(input_ids = batch['input_ids'], attention_mask = batch['attention_mask'], labels1=labels1, labels2=labels2)\n",
        "    print(loss)\n",
        "    print(logits1)\n",
        "    print(labels2)\n",
        "\n",
        "    output2label(logits1, logits2, label_to_site_dict)\n",
        "    print(f\"Label: {labels2}\")\n",
        "    print(get_metrics(logits1, logits2, labels2))\n",
        "    print(\"-\"*60, \"\\n\")\n",
        "\n",
        "\n",
        "    break"
      ],
      "metadata": {
        "id": "Au_MB4RAS8pq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 추론 테스트"
      ],
      "metadata": {
        "id": "5IWU4gu-3Fho"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# 입력 텍스트\n",
        "input_text = \"뉴스 국회 최근 합법화 국회의원 국민 헌법 법 제정\"\n",
        "\n",
        "# 텍스트를 토큰화\n",
        "inputs = tokenizer(input_text, return_tensors=\"pt\", padding=True, truncation=True, max_length=512)\n",
        "\n",
        "# 입력에 대한 추론 (추론에서는 gradient 필요없음)\n",
        "\n",
        "model.eval()\n",
        "\n",
        "with torch.no_grad():\n",
        "    input_ids = inputs['input_ids'].to(DEVICE)\n",
        "    attention_mask = inputs['attention_mask'].to(DEVICE)\n",
        "\n",
        "    # 1단계 모델에 입력\n",
        "    output1 = model.distilbert1(input_ids=input_ids, attention_mask=attention_mask)\n",
        "    logits1 = output1.logits\n",
        "\n",
        "    hidden1 = output1.hidden_states[-1]  # 마지막 레이어의 hidden state\n",
        "    output2 = model.distilbert2(inputs_embeds=hidden1, attention_mask=attention_mask)\n",
        "    logits2 = output2.logits\n",
        "    output2label(logits1, logits2, label_to_site_dict)\n"
      ],
      "metadata": {
        "id": "8mrcNwvKqtZW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 학습 파라미터 지정"
      ],
      "metadata": {
        "id": "LphIlFrERT39"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 파인튜닝 시작"
      ],
      "metadata": {
        "id": "mxtHKSMBdJaX"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Early Stopping 커스텀 클래스 선언\n",
        "class EarlyStopping:\n",
        "  def __init__(self, patience = 3, min_delta = 0):\n",
        "    \"\"\"\n",
        "    Args:\n",
        "        patience: 몇 번 연속으로 성능향상이 없을 때 종료할 것인지\n",
        "        min_delta: 성능 향상의 최소치\n",
        "    \"\"\"\n",
        "    self.patience = patience\n",
        "    self.min_delta = min_delta\n",
        "    self.counter = 0\n",
        "    self.best_loss = None\n",
        "    self.early_stop = False\n",
        "\n",
        "  def __call__(self, val_loss):\n",
        "    if self.best_loss is None:\n",
        "      self.best_loss = val_loss\n",
        "    elif val_loss < (self.best_loss - self.min_delta):\n",
        "      self.best_loss = val_loss\n",
        "      self.counter = 0\n",
        "    else:\n",
        "      self.counter +=1\n",
        "      if self.counter >= self.patience:\n",
        "        self.early_stop = True\n"
      ],
      "metadata": {
        "id": "jQ6-FFUCfFO3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 파인튜닝을 위한 함수 선언\n",
        "def fine_tuning(model, train_DL, val_DL, resume_training):\n",
        "\n",
        "  early_stopping = EarlyStopping(patience = 4)\n",
        "\n",
        "  # 학습이 중단된 모델일 경우에는 기존에 학습한 히스토리를 불러옴\n",
        "  if resume_training:\n",
        "    start = start_epoch\n",
        "    total_train_loss = train_loss\n",
        "    total_train_acc =  train_acc\n",
        "    total_val_loss = val_loss\n",
        "    total_val_acc = val_acc\n",
        "    total_train_f1 = train_f1\n",
        "    total_val_f1 = val_f1\n",
        "\n",
        "  else:\n",
        "    start = 0\n",
        "    total_train_loss = []\n",
        "    total_train_acc =  []\n",
        "    total_val_loss = []\n",
        "    total_val_acc = []\n",
        "    total_train_f1 = []\n",
        "    total_val_f1 = []\n",
        "\n",
        "  N = len(val_DL)\n",
        "\n",
        "  # EPoch만큼 반복\n",
        "  for epoch in range(start, EPOCH):\n",
        "    model.train()\n",
        "    total_loss = 0\n",
        "    total_acc = 0\n",
        "    val_loss_batch = 0\n",
        "    val_acc_batch = 0\n",
        "\n",
        "    TP_batch = 0\n",
        "    FP_batch = 0\n",
        "    FN_batch = 0\n",
        "\n",
        "    TP_batch_val = 0\n",
        "    FP_batch_val = 0\n",
        "    FN_batch_val = 0\n",
        "\n",
        "    tqdm_batch = tqdm(train_DL, desc = f\"Epoch {epoch + 1} / {EPOCH}\")\n",
        "    i = 1\n",
        "\n",
        "    for batch in tqdm_batch:\n",
        "      batch = {key: value.to(DEVICE) for key, value in batch.items()} # gpu에 올라간 모델에 데이터를 넣어주기 위해서 데이터도 gpu에 올리기\n",
        "      labels1 = batch['labels']  # 첫 번째 분류용 라벨\n",
        "      labels1 = torch.where(labels1 ==0, 0, 1)\n",
        "\n",
        "      labels2 = batch['labels']  # 두 번째 분류용 라벨\n",
        "\n",
        "\n",
        "      optimizer.zero_grad() # gradient가 쌓이지 않도록 초기화\n",
        "      loss, logits1, logits2 = model(input_ids = batch['input_ids'], attention_mask = batch['attention_mask'], labels1=labels1, labels2=labels2) #데이터 입력\n",
        "      loss.backward() #back-propagation\n",
        "      optimizer.step()\n",
        "      scheduler.step()\n",
        "\n",
        "      total_loss += loss.item()\n",
        "      tqdm_batch.set_postfix(loss = total_loss / i) #학습상태를 알기위해서 tqdm에 loss를 계속 설정해준다\n",
        "      i += 1\n",
        "\n",
        "      batch_acc, TP, FP, FN, _ = get_metrics(logits1, logits2, labels2)\n",
        "      total_acc += batch_acc\n",
        "      TP_batch += TP\n",
        "      FP_batch += FP\n",
        "      FN_batch += FN\n",
        "\n",
        "\n",
        "    # 한 에폭마다 훈련 결과 저장\n",
        "    # f1-score = (2 x TP) / (2 x TP + FP + FN)\n",
        "    total_train_loss.append(total_loss/ len(train_DL))\n",
        "    total_train_acc.append(total_acc / (len(train_DL) * batch_size))\n",
        "    total_train_f1.append((2 * TP_batch) / (2 * TP_batch + FP_batch + FN_batch))\n",
        "\n",
        "\n",
        "    # Validation\n",
        "    model.eval()\n",
        "    tqdm_batch_val = tqdm(val_DL, desc = f\"Validation\")\n",
        "    j = 1\n",
        "    with torch.no_grad():\n",
        "      for batch in tqdm_batch_val:\n",
        "\n",
        "\n",
        "        batch = {key: value.to(DEVICE) for key, value in batch.items()}\n",
        "        labels1 = batch['labels']  # 첫 번째 분류용 라벨\n",
        "        labels1 = torch.where(labels1 ==0, 0, 1)\n",
        "\n",
        "        labels2 = batch['labels']  # 두 번째 분류용 라벨\n",
        "\n",
        "        loss, logits1, logits2 = model(input_ids = batch['input_ids'], attention_mask = batch['attention_mask'], labels1=labels1, labels2=labels2)\n",
        "\n",
        "        val_loss_batch += loss.item()\n",
        "        tqdm_batch_val.set_postfix(loss = val_loss_batch / j)\n",
        "        j +=1\n",
        "\n",
        "        batch_acc, TP, FP, FN, _ = get_metrics(logits1, logits2, labels2)\n",
        "        val_acc_batch += batch_acc\n",
        "        TP_batch_val += TP\n",
        "        FP_batch_val += FP\n",
        "        FN_batch_val += FN\n",
        "\n",
        "      total_val_loss.append(val_loss_batch / len(val_DL))\n",
        "      total_val_acc.append(val_acc_batch / (len(val_DL) * batch_size))\n",
        "      total_val_f1.append((2 * TP_batch_val) / (2 * TP_batch_val + FP_batch_val + FN_batch_val))\n",
        "\n",
        "      #조기종료\n",
        "      early_stopping(val_loss_batch / N)\n",
        "\n",
        "      if early_stopping.early_stop:\n",
        "        print(\"\\nEarly Stopping is Triggered!!!!\")\n",
        "        break\n",
        "      print(f'Accuracy: {val_acc_batch / (N * batch_size)}%')\n",
        "\n",
        "    #각 에폭마다 모델과 히스토리 저장\n",
        "    save_checkpoint(model, optimizer, scheduler, epoch, loss, save_model_path)\n",
        "    save_hist(total_train_loss, total_train_acc, total_val_loss, total_val_acc, total_train_f1, total_val_f1, save_hist_path)\n",
        "\n"
      ],
      "metadata": {
        "id": "YHatcrGxdJpG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "fine_tuning(model, train_DL, val_DL, resume_training) #파인튜닝 실행"
      ],
      "metadata": {
        "id": "imDaOo_ldJtf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 훈련결과 시각화"
      ],
      "metadata": {
        "id": "h-TWVU5K7e7x"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# 히스토리 데이터 불러오기\n",
        "hist_data = torch.load(save_hist_path)\n",
        "\n",
        "train_loss =  hist_data[\"train_loss_list\"]\n",
        "train_acc = hist_data[\"train_acc_list\"]\n",
        "val_loss = hist_data[\"val_loss_list\"]\n",
        "val_acc = hist_data[\"val_acc_list\"]\n",
        "\n",
        "fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(12, 5))\n",
        "\n",
        "# 첫 번째 그래프: Train Loss\n",
        "ax1.plot(range(1, len(train_loss) + 1), train_loss, label='Train', color='r')\n",
        "ax1.plot(range(1, len(val_loss) + 1), val_loss, label='Val', color='b')\n",
        "ax1.set_title('Loss')\n",
        "ax1.set_xlabel('Epochs')\n",
        "ax1.set_ylabel('Loss')\n",
        "ax1.legend()\n",
        "\n",
        "# 두 번째 그래프: Validation Loss\n",
        "ax2.plot(range(1, len(train_acc) + 1), train_acc, label='Train', color='r')\n",
        "ax2.plot(range(1, len(val_acc) + 1), val_acc, label='Val', color='b')\n",
        "ax2.set_title('Accuracy')\n",
        "ax2.set_xlabel('Epochs')\n",
        "ax2.set_ylabel('Accuracy')\n",
        "ax2.legend()\n",
        "\n",
        "\n",
        "# 레이아웃 자동 조정\n",
        "plt.tight_layout()\n",
        "\n",
        "# 그래프 출력\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "qdZf-ZQAmBs6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_f1 = hist_data[\"train_f1_list\"]\n",
        "val_f1 = hist_data[\"val_f1_list\"]\n",
        "\n",
        "plt.plot(range(1, len(train_f1) + 1), train_f1, label = 'Train', color = 'r')\n",
        "plt.plot(range(1, len(val_f1) + 1), val_f1, label = 'Val', color = 'b')\n",
        "plt.title(\"F1-Score\")\n",
        "plt.xlabel('Epochs')\n",
        "plt.ylabel('F1-Score')\n",
        "plt.legend()\n",
        "\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "N8nmZ5aLmBy_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 정확도 및 f1-score 확인\n",
        "print(f\"Validation Accuracy: {val_acc[-1]:.3%}\")\n",
        "print(f\"F1-Score: {val_f1[-1]:.3%}\")"
      ],
      "metadata": {
        "id": "RxyZVE2JMLt1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(f\"Validation Accuracy: {max(val_acc):.3%}\")\n",
        "print(f\"F1-Score: {max(val_f1):.3%}\")"
      ],
      "metadata": {
        "id": "OcfvDJt1Nt1_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "levkTr4FC0Zy"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}